{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d992763-2eef-4982-bc2a-8e0cd08254ed",
   "metadata": {},
   "source": [
    "# Correctionlib to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1a2b8eb-fd42-46ea-822e-7c16c60fa551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import correctionlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b53802-ed70-4830-a666-c58e826e4933",
   "metadata": {},
   "source": [
    "### Setting up some global parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de4d9ed-e4c8-44e2-973f-4b0cc7166a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objectdict = {\n",
    "    'Electron':{\n",
    "        'basedir':'POG/EGM/',\n",
    "        'jsonfile': 'electron.json',\n",
    "        'corrections':{\n",
    "            'UL-Electron-ID-SF':  'electron_id_sf.txt'\n",
    "        },\n",
    "        'outdir':'corrections/electronsf'\n",
    "    },\n",
    "    'Muon':{\n",
    "        'basedir':'POG/MUO/',\n",
    "        'jsonfile': 'muon_Z_v2.json',\n",
    "        'corrections':{\n",
    "            'NUM_MediumID_DEN_genTracks':  'muon_id_sf.txt',\n",
    "            'NUM_TightRelIso_DEN_MediumID':'muon_iso_sf.txt'\n",
    "        },\n",
    "        'outdir':'corrections/muonsf'\n",
    "    },\n",
    "    'Jet-JEC':{\n",
    "        'basedir':'POG/JME/',\n",
    "        'jsonfile': 'jet_jerc.json',\n",
    "        'corrections':{\n",
    "            'Summer19UL18_V5_MC_Total_AK4PFchs': 'jet_jec_sf.txt',\n",
    "        },\n",
    "        'outdir':'corrections/jetsf'\n",
    "    },\n",
    "    'Jet-JER':{\n",
    "        'basedir':'POG/JME/',\n",
    "        'jsonfile': 'jet_jerc.json',\n",
    "        'corrections':{\n",
    "            'Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs': 'jet_jer_sf.txt',\n",
    "        },\n",
    "        'outdir':'corrections/jetsf'\n",
    "    },\n",
    "    'Jet-pT':{\n",
    "        'basedir':'POG/JME/',\n",
    "        'jsonfile': 'jet_jerc.json',\n",
    "        'corrections':{\n",
    "            'Summer19UL18_JRV2_MC_PtResolution_AK4PFchs': 'jet_ptres_sf.txt',\n",
    "        },\n",
    "        'outdir':'corrections/jetsf'\n",
    "    },\n",
    "    'bJet':{\n",
    "        'basedir':'POG/BTV/',\n",
    "        'jsonfile': 'btagging.json',\n",
    "        'corrections':{\n",
    "            'deepJet_mujets': 'bjet_mujets_and_incl_eff.txt',\n",
    "            'deepJet_comb': 'bjet_comb_and_incl_eff.txt'\n",
    "        },\n",
    "        'outdir':'corrections/bjeteff'\n",
    "    }\n",
    "}\n",
    "\n",
    "def warning(text):\n",
    "    text = '\\033[031mWarning! '+text+'\\033[0m'\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cac86bf-e9f4-4a82-92ff-b88d066326d5",
   "metadata": {},
   "source": [
    "#### Extracting electron scale-factors in pT-eta bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50407b0b-3c92-4822-90c2-b2450811dde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function for electrons loaded.\n"
     ]
    }
   ],
   "source": [
    "def parse_electron_sf(filename, correction_name, campaign):\n",
    "    scale_factors = []\n",
    "    with open(filename, \"r\") as f: json_data = json.load(f)\n",
    "\n",
    "    pt_edges = None\n",
    "    eta_edges = None\n",
    "\n",
    "    for item in json_data['corrections']:\n",
    "        #Each item is a dict\n",
    "        if item['name'] != correction_name: continue\n",
    "        \n",
    "        content = item['data']['content']\n",
    "        for obj in content:\n",
    "            ### campaign name\n",
    "            if obj['key'] not in campaign: continue\n",
    "            print('Extracting data for: '+obj['key'])\n",
    "            \n",
    "            subcontent = obj['value']['content']\n",
    "            for subobj in subcontent:\n",
    "                ### sf type\n",
    "                if subobj['key'] != 'sf':continue\n",
    "                print('Extracting data for:'+subobj['key'])\n",
    "\n",
    "                subsubcontent = subobj['value']['content']\n",
    "                for subsubobj in subsubcontent:\n",
    "                    ### Working point\n",
    "                    if subsubobj['key'] != 'Medium': continue\n",
    "                    print('Extracting data for '+subsubobj['key']+' WP')\n",
    "\n",
    "                    edges = subsubobj['value']['edges']\n",
    "                    eta_edges = edges[0]\n",
    "                    pt_edges  = edges[1]\n",
    "                    print('Edges extracted!')\n",
    "\n",
    "    # Now that the binning is calculated,\n",
    "    #print(pt_edges)\n",
    "    #print(eta_edges)\n",
    "    correction_set = correctionlib.CorrectionSet.from_file(filename)\n",
    "    correction = correction_set[correction_name]\n",
    "    MAX_PT = 1500\n",
    "    MIN_ETA = -2.5\n",
    "    MAX_ETA = 2.5\n",
    "    \n",
    "    #Given the pt and eta edges, loop over their midvalues.\n",
    "    for eta_low, eta_high in zip(eta_edges[:-1], eta_edges[1:]):\n",
    "        for pt_low, pt_high in zip(pt_edges[:-1], pt_edges[1:]):\n",
    "\n",
    "            if not np.isfinite(eta_low):  eta_low  = MIN_ETA if eta_low == -np.inf else MAX_ETA\n",
    "            if not np.isfinite(eta_high): eta_high = MIN_ETA if eta_high == -np.inf else MAX_ETA\n",
    "            if not np.isfinite(pt_low):     pt_low = MAX_PT if pt_low == np.inf else 0\n",
    "            if not np.isfinite(pt_high):   pt_high = MAX_PT if pt_high == np.inf else 0 \n",
    "            \n",
    "            eta = (eta_low + eta_high) / 2\n",
    "            pt  = (pt_low  + pt_high) / 2\n",
    "            era = campaign.replace('_UL', '')\n",
    "            wp = \"Medium\"\n",
    "            values = [era, 'sf', wp, eta, pt]\n",
    "            values_down = [era, 'sfdown', wp, eta, pt]\n",
    "            values_up = [era, 'sfup', wp, eta, pt]\n",
    "            sfdown = correction.evaluate(*values_down)\n",
    "            sf = correction.evaluate(*values)\n",
    "            sfup = correction.evaluate(*values_up)\n",
    "            \n",
    "            scale_factors.append({\n",
    "                'campaign': campaign,\n",
    "                'eta_low' : eta_low,\n",
    "                'eta_high': eta_high, \n",
    "                'pt_low'  : pt_low,\n",
    "                'pt_high' : pt_high,\n",
    "                'sfdown'  : sfdown,\n",
    "                'sf'      : sf,\n",
    "                'sfup'    : sfup\n",
    "            })\n",
    "\n",
    "            #print(f\"Scale factor: {sf}, sfdown: {sfdown}, sfup: {sfup}\")\n",
    "            #break ### ptbin\n",
    "        #break ### etabin\n",
    "   \n",
    "    df = pd.DataFrame(scale_factors)\n",
    "    print('Correctionlib evaluated and dataframe created.\\n')\n",
    "    return df\n",
    "\n",
    "print('Function for electrons loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063687f6-3b75-4828-b7b7-259e7ee01b2b",
   "metadata": {},
   "source": [
    "#### Extracting muon scale-factors in pT-eta bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04b13a07-453e-41f1-a95d-87baccd16827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function for muons loaded.\n"
     ]
    }
   ],
   "source": [
    "def parse_muon_sf(filename, correction_name, campaign):\n",
    "    scale_factors=[]\n",
    "    with open(filename, \"r\") as f: json_data = json.load(f)\n",
    "\n",
    "    pt_edges = None\n",
    "    eta_edges = None\n",
    "\n",
    "    for item in json_data['corrections']:\n",
    "        #Each item is a dict\n",
    "        if item['name'] != correction_name: continue\n",
    "\n",
    "        content = item['data']['content']\n",
    "        for obj in content:\n",
    "            ### eta bins\n",
    "            if obj['key'] not in campaign: continue\n",
    "            print('Extracting data for: '+obj['key'])\n",
    "            eta_edges = obj['value']['edges']\n",
    "            subcontent = obj['value']['content']\n",
    "            for subobj in subcontent:\n",
    "                ### pt bins\n",
    "                pt_edges = subobj['edges']\n",
    "                print('Edges extracted!')\n",
    "                break ### found pt endges\n",
    "\n",
    "    # Now that the binning is calculated,\n",
    "    #print(pt_edges)\n",
    "    #print(eta_edges)\n",
    "    correction_set = correctionlib.CorrectionSet.from_file(filename)\n",
    "    correction = correction_set[correction_name]\n",
    "    MAX_PT = 1500\n",
    "    MIN_ETA = 0\n",
    "    MAX_ETA = 2.5\n",
    "    \n",
    "    #Given the pt and eta edges, loop over their midvalues.\n",
    "    for eta_low, eta_high in zip(eta_edges[:-1], eta_edges[1:]):\n",
    "        for pt_low, pt_high in zip(pt_edges[:-1], pt_edges[1:]):\n",
    "            if not np.isfinite(pt_high):   pt_high = MAX_PT if pt_high == np.inf else 0\n",
    "\n",
    "            eta = (eta_low + eta_high) / 2\n",
    "            pt  = (pt_low  + pt_high) / 2\n",
    "            era = campaign\n",
    "            values = [era, eta, pt, 'sf']\n",
    "            values_down = [era, eta, pt, 'systdown']\n",
    "            values_up = [era, eta, pt, 'systup']\n",
    "            sfdown = correction.evaluate(*values_down)\n",
    "            sf = correction.evaluate(*values)\n",
    "            sfup = correction.evaluate(*values_up)\n",
    "            \n",
    "            scale_factors.append({\n",
    "                'campaign': campaign,\n",
    "                'eta_low' : eta_low,\n",
    "                'eta_high': eta_high, \n",
    "                'pt_low'  : pt_low,\n",
    "                'pt_high' : pt_high,\n",
    "                'sfdown'  : sfdown,\n",
    "                'sf'      : sf,\n",
    "                'sfup'    : sfup\n",
    "            })\n",
    "                \n",
    "    df = pd.DataFrame(scale_factors)\n",
    "    return df\n",
    "\n",
    "print('Function for muons loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd85c80-9f76-41b1-a8c3-dcf8c9e0fd05",
   "metadata": {},
   "source": [
    "#### Extracting JEC and JER in pT-eta bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655391f8-0221-4e50-8739-94932354f7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function for jets loaded.\n"
     ]
    }
   ],
   "source": [
    "def parse_jet_jec_sf(filename, correction_name, campaign):\n",
    "    scale_factors=[]\n",
    "    with open(filename, \"r\") as f: json_data = json.load(f)\n",
    "\n",
    "    pt_edges = None\n",
    "    eta_edges = None\n",
    "\n",
    "    match_found = False\n",
    "    for item in json_data['corrections']:\n",
    "        if item['name'] != correction_name: continue\n",
    "        match_found = True\n",
    "            \n",
    "        #print(item['data'].keys())\n",
    "        #print(item['data']['input'])\n",
    "        #print(item['data']['edges'])\n",
    "        eta_edges = item['data']['edges']\n",
    "        content = item['data']['content']\n",
    "        for obj in content:\n",
    "            #print(obj.keys())\n",
    "            #print(obj['input'])\n",
    "            #print(obj['edges'])\n",
    "            pt_edges = obj['edges']\n",
    "            print('Edges extracted!')\n",
    "            break\n",
    "\n",
    "    if not match_found: warning(f'Not found: {correction_name}')\n",
    "    if eta_edges ==None or pt_edges == None: return pd.DataFrame([])\n",
    "    #print(f'JEC pT edges = {pt_edges}')\n",
    "    #print(f'JEC eta edges = {eta_edges}')\n",
    "\n",
    "    # Now that the binning is calculated,\n",
    "    correction_set = correctionlib.CorrectionSet.from_file(filename)\n",
    "    correction = correction_set[correction_name]\n",
    "    \n",
    "    #Given the pt and eta edges, loop over their midvalues.\n",
    "    for eta_low, eta_high in zip(eta_edges[:-1], eta_edges[1:]):\n",
    "        for pt_low, pt_high in zip(pt_edges[:-1], pt_edges[1:]):\n",
    "            \n",
    "            eta = (eta_low + eta_high) / 2\n",
    "            pt  = (pt_low  + pt_high) / 2\n",
    "            values = [eta, pt]\n",
    "            unc = correction.evaluate(*values)\n",
    "            sf = np.ones_like(unc)\n",
    "            \n",
    "            scale_factors.append({\n",
    "                'campaign': campaign,\n",
    "                'eta_low' : eta_low,\n",
    "                'eta_high': eta_high, \n",
    "                'pt_low'  : pt_low,\n",
    "                'pt_high' : pt_high,\n",
    "                'sfdown'  : sf-unc,\n",
    "                'sf'      : sf,\n",
    "                'sfup'    : sf+unc\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(scale_factors)\n",
    "    return df\n",
    "\n",
    "def parse_jet_jer_sf(filename, correction_name, campaign):\n",
    "\n",
    "    scale_factors=[]\n",
    "    with open(filename, \"r\") as f: json_data = json.load(f)\n",
    "\n",
    "    pt_edges = None\n",
    "    eta_edges = None\n",
    "\n",
    "    match_found = False\n",
    "    for item in json_data['corrections']:\n",
    "        if item['name'] != correction_name: continue\n",
    "        match_found = True\n",
    "\n",
    "        #print(item['data'].keys())\n",
    "        #print(item['data']['input'])\n",
    "        #print(item['data']['edges'])\n",
    "        eta_edges = item['data']['edges']\n",
    "        print('Edges extracted!')\n",
    "\n",
    "    if not match_found: warning(f'Not found: {correction_name}')\n",
    "    #if eta_edges ==None or pt_edges == None: return pd.DataFrame([])\n",
    "    #print(f'JER eta edges = {eta_edges}')\n",
    "    \n",
    "    correction_set = correctionlib.CorrectionSet.from_file(filename)\n",
    "    correction = correction_set[correction_name]\n",
    "    for eta_low, eta_high in zip(eta_edges[:-1], eta_edges[1:]):\n",
    "        \n",
    "        eta = (eta_low + eta_high) / 2\n",
    "        values_nom = [eta, 'nom']\n",
    "        values_up  = [eta, 'up']\n",
    "        values_down = [eta, 'down']\n",
    "        \n",
    "        sf     = correction.evaluate(*values_nom)\n",
    "        sfup   = correction.evaluate(*values_up)\n",
    "        sfdown = correction.evaluate(*values_down)\n",
    "        \n",
    "        scale_factors.append({\n",
    "            'campaign': campaign,\n",
    "            'eta_low' : eta_low,\n",
    "            'eta_high': eta_high,\n",
    "            'sfdown'  : sfdown,\n",
    "            'sf'      : sf,\n",
    "            'sfup'    : sfup\n",
    "        })\n",
    "            \n",
    "    df = pd.DataFrame(scale_factors)\n",
    "    return df\n",
    "\n",
    "def parse_jet_ptres_sf(filename, correction_name, campaign):\n",
    "\n",
    "    scale_factors=[]\n",
    "    with open(filename, \"r\") as f: json_data = json.load(f)\n",
    "\n",
    "    # This is a function based correction. So pT ednges are not available.\n",
    "    # In order to write in the text file, I pciked the same pT edges as in JEC and JER\n",
    "    pt_edges = [9.0, 11.0, 13.5, 16.5, 19.5, 22.5, 26.0, 30.0, 34.5, 40.0,\n",
    "                46.0, 52.5, 60.0, 69.0, 79.0, 90.5, 105.5, 123.5, 143.0,\n",
    "                163.5, 185.0, 208.0, 232.5, 258.5, 286.0, 331.0, 396.0,\n",
    "                468.5, 549.5, 639.0, 738.0, 847.5, 968.5, 1102.0, 1249.5,\n",
    "                1412.0, 1590.5, 1787.0, 2003.0, 2241.0, 2503.0, 2790.5, 3107.0,\n",
    "                3455.0, 3837.0, 4257.0, 4719.0, 5226.5, 5784.0, 6538.0]\n",
    "    \n",
    "    eta_edges = None\n",
    "    rho_edges = None\n",
    "\n",
    "    match_found = False\n",
    "    for item in json_data['corrections']:\n",
    "        if item['name'] != correction_name: continue\n",
    "        match_found = True\n",
    "\n",
    "        eta_edges = item['data']['edges']\n",
    "        content = item['data']['content']\n",
    "        for obj in content:\n",
    "            rho_edges = obj['edges']\n",
    "            print('Edges extracted!')\n",
    "            break\n",
    "\n",
    "    #print(f'pT-res eta edges = {eta_edges}')\n",
    "    #print(f'pT-res rho edges = {rho_edges}')\n",
    "\n",
    "    if not match_found: warning(f'Not found: {correction_name}')\n",
    "\n",
    "    # Now that the binning is calculated,\n",
    "    correction_set = correctionlib.CorrectionSet.from_file(filename)\n",
    "    correction = correction_set[correction_name]\n",
    "    \n",
    "    #Given the pt and eta edges, loop over their midvalues.\n",
    "    for eta_low, eta_high in zip(eta_edges[:-1], eta_edges[1:]):\n",
    "        for pt_low, pt_high in zip(pt_edges[:-1], pt_edges[1:]):\n",
    "            for rho_low, rho_high in zip(rho_edges[:-1], rho_edges[1:]):\n",
    "            \n",
    "                eta = (eta_low + eta_high) / 2\n",
    "                pt  = (pt_low  + pt_high) / 2\n",
    "                rho  = (rho_low  + rho_high) / 2\n",
    "                values = [eta, pt, rho]\n",
    "                sf = correction.evaluate(*values)\n",
    "                \n",
    "                scale_factors.append({\n",
    "                    'campaign': campaign,\n",
    "                    'eta_low' : eta_low,\n",
    "                    'eta_high': eta_high, \n",
    "                    'pt_low'  : pt_low,\n",
    "                    'pt_high' : pt_high,\n",
    "                    'rho_low'  : rho_low,\n",
    "                    'rho_high' : rho_high,\n",
    "                    'sf'      : sf,\n",
    "                })\n",
    "    \n",
    "    df = pd.DataFrame(scale_factors)\n",
    "    return df\n",
    "\n",
    "print('Function for jets loaded.')      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db14dd96-3c6d-4769-a059-10672ffc1abf",
   "metadata": {},
   "source": [
    "### b-tagging / mis-tagging efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711e019f-5217-4c7d-9c4c-00c072c04606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function for b-jets loaded.\n"
     ]
    }
   ],
   "source": [
    "def parse_bjet_eff(filename, correction_name, campaign):\n",
    "\n",
    "    scale_factors=[]\n",
    "    with open(filename, \"r\") as f: json_data = json.load(f)\n",
    "\n",
    "    pt_edges     = [20.0, 30.0, 50.0, 70.0, 100.0, 140.0, 200.0, 300.0, 600.0, 1000.0] #Taken from the input file\n",
    "    eta_edges = [0, 2.5] #Taken from the input file\n",
    "    flavors = [0, 5, 4]\n",
    "\n",
    "    correction_set = correctionlib.CorrectionSet.from_file(filename)\n",
    "    for flav in flavors:\n",
    "        for eta_low, eta_high in zip(eta_edges[:-1], eta_edges[1:]):\n",
    "            for pt_low, pt_high in zip(pt_edges[:-1], pt_edges[1:]):\n",
    "                \n",
    "                eta = (eta_low + eta_high) / 2\n",
    "                pt  = (pt_low  + pt_high) / 2\n",
    "                wp = 'M'\n",
    "                if flav in [4, 5]: correction = correction_set[correction_name] #For b and c jets\n",
    "                else: correction = correction_set['deepJet_incl'] #for light jets\n",
    "\n",
    "                values      = ['central', 'M', flav, eta, pt]\n",
    "                values_up   = ['up', 'M', flav, eta, pt]\n",
    "                values_down = ['down', 'M', flav, eta, pt]\n",
    "                #Options: central, up, up_correlated, up_uncorrelated, down, down_correlated, down_uncorrelated\n",
    "\n",
    "                sf     = correction.evaluate(*values)\n",
    "                sfup   = correction.evaluate(*values_up)\n",
    "                sfdown = correction.evaluate(*values_down)\n",
    "                \n",
    "                scale_factors.append({\n",
    "                    'campaign': campaign,\n",
    "                    'eta_low' : eta_low,\n",
    "                    'eta_high': eta_high, \n",
    "                    'pt_low'  : pt_low,\n",
    "                    'pt_high' : pt_high,\n",
    "                    'flav'    : flav,\n",
    "                    'sfdown'  : sfdown,\n",
    "                    'sf'      : sf,\n",
    "                    'sfup'    : sfup\n",
    "                })   \n",
    "    \n",
    "    df = pd.DataFrame(scale_factors)\n",
    "    return df\n",
    "\n",
    "print('Function for b-jets loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24310cb-8a71-4413-89bf-a93163f28c2e",
   "metadata": {},
   "source": [
    "## Main: Iterating over the object dictionary to find scale-factors for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bebdd9a9-7e04-486b-8f04-546d5e57b468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "\u001b[032mProcessing corrections for: Electron\u001b[0m\n",
      "--------------------------------------------------\n",
      "\n",
      "\u001b[033mProcessing correction: UL-Electron-ID-SF\u001b[0m\n",
      "\n",
      "Opening file: POG/EGM/2016postVFP_UL/electron.json for correction: UL-Electron-ID-SF\n",
      "Extracting data for: 2016postVFP\n",
      "Extracting data for:sf\n",
      "Extracting data for Medium WP\n",
      "Edges extracted!\n",
      "Correctionlib evaluated and dataframe created.\n",
      "\n",
      "Opening file: POG/EGM/2016preVFP_UL/electron.json for correction: UL-Electron-ID-SF\n",
      "Extracting data for: 2016preVFP\n",
      "Extracting data for:sf\n",
      "Extracting data for Medium WP\n",
      "Edges extracted!\n",
      "Correctionlib evaluated and dataframe created.\n",
      "\n",
      "Opening file: POG/EGM/2017_UL/electron.json for correction: UL-Electron-ID-SF\n",
      "Extracting data for: 2017\n",
      "Extracting data for:sf\n",
      "Extracting data for Medium WP\n",
      "Edges extracted!\n",
      "Correctionlib evaluated and dataframe created.\n",
      "\n",
      "Opening file: POG/EGM/2018_UL/electron.json for correction: UL-Electron-ID-SF\n",
      "Extracting data for: 2018\n",
      "Extracting data for:sf\n",
      "Extracting data for Medium WP\n",
      "Edges extracted!\n",
      "Correctionlib evaluated and dataframe created.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.024601</td>\n",
       "      <td>1.039711</td>\n",
       "      <td>1.054822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.999609</td>\n",
       "      <td>1.015896</td>\n",
       "      <td>1.032183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.972655</td>\n",
       "      <td>0.985459</td>\n",
       "      <td>0.998263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.881451</td>\n",
       "      <td>0.933747</td>\n",
       "      <td>0.986044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  eta_low  eta_high  pt_low  pt_high    sfdown        sf  \\\n",
       "0    2016postVFP_UL     -2.5      -2.0    10.0     20.0  1.024601  1.039711   \n",
       "1    2016postVFP_UL     -2.5      -2.0    20.0     35.0  0.999609  1.015896   \n",
       "218         2018_UL      2.0       2.5   100.0    200.0  0.972655  0.985459   \n",
       "219         2018_UL      2.0       2.5   200.0   1500.0  0.881451  0.933747   \n",
       "\n",
       "         sfup  \n",
       "0    1.054822  \n",
       "1    1.032183  \n",
       "218  0.998263  \n",
       "219  0.986044  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/electronsf/electron_id_sf.txt\n",
      "\n",
      "--------------------------------------------------\n",
      "\u001b[032mProcessing corrections for: Muon\u001b[0m\n",
      "--------------------------------------------------\n",
      "\n",
      "\u001b[033mProcessing correction: NUM_MediumID_DEN_genTracks\u001b[0m\n",
      "\n",
      "Opening file: POG/MUO/2016postVFP_UL/muon_Z_v2.json for correction: NUM_MediumID_DEN_genTracks\n",
      "Extracting data for: 2016postVFP_UL\n",
      "Edges extracted!\n",
      "Opening file: POG/MUO/2016preVFP_UL/muon_Z_v2.json for correction: NUM_MediumID_DEN_genTracks\n",
      "Extracting data for: 2016preVFP_UL\n",
      "Edges extracted!\n",
      "Opening file: POG/MUO/2017_UL/muon_Z_v2.json for correction: NUM_MediumID_DEN_genTracks\n",
      "Extracting data for: 2017_UL\n",
      "Edges extracted!\n",
      "Opening file: POG/MUO/2018_UL/muon_Z_v2.json for correction: NUM_MediumID_DEN_genTracks\n",
      "Extracting data for: 2018_UL\n",
      "Edges extracted!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.769809</td>\n",
       "      <td>1.063897</td>\n",
       "      <td>1.357984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.953175</td>\n",
       "      <td>0.991884</td>\n",
       "      <td>1.030593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.920821</td>\n",
       "      <td>0.944989</td>\n",
       "      <td>0.969157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.920821</td>\n",
       "      <td>0.944989</td>\n",
       "      <td>0.969157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  eta_low  eta_high  pt_low  pt_high    sfdown        sf  \\\n",
       "0    2016postVFP_UL      0.0       0.9    15.0     20.0  0.769809  1.063897   \n",
       "1    2016postVFP_UL      0.0       0.9    20.0     25.0  0.953175  0.991884   \n",
       "126         2018_UL      2.1       2.4    60.0    120.0  0.920821  0.944989   \n",
       "127         2018_UL      2.1       2.4   120.0   1500.0  0.920821  0.944989   \n",
       "\n",
       "         sfup  \n",
       "0    1.357984  \n",
       "1    1.030593  \n",
       "126  0.969157  \n",
       "127  0.969157  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/muonsf/muon_id_sf.txt\n",
      "\n",
      "\u001b[033mProcessing correction: NUM_TightRelIso_DEN_MediumID\u001b[0m\n",
      "\n",
      "Opening file: POG/MUO/2016postVFP_UL/muon_Z_v2.json for correction: NUM_TightRelIso_DEN_MediumID\n",
      "Extracting data for: 2016postVFP_UL\n",
      "Edges extracted!\n",
      "Opening file: POG/MUO/2016preVFP_UL/muon_Z_v2.json for correction: NUM_TightRelIso_DEN_MediumID\n",
      "Extracting data for: 2016preVFP_UL\n",
      "Edges extracted!\n",
      "Opening file: POG/MUO/2017_UL/muon_Z_v2.json for correction: NUM_TightRelIso_DEN_MediumID\n",
      "Extracting data for: 2017_UL\n",
      "Edges extracted!\n",
      "Opening file: POG/MUO/2018_UL/muon_Z_v2.json for correction: NUM_TightRelIso_DEN_MediumID\n",
      "Extracting data for: 2018_UL\n",
      "Edges extracted!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.977739</td>\n",
       "      <td>0.989664</td>\n",
       "      <td>1.001588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.984609</td>\n",
       "      <td>0.994829</td>\n",
       "      <td>1.005048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.001259</td>\n",
       "      <td>1.002989</td>\n",
       "      <td>1.004718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1.001259</td>\n",
       "      <td>1.002989</td>\n",
       "      <td>1.004718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  eta_low  eta_high  pt_low  pt_high    sfdown        sf  \\\n",
       "0    2016postVFP_UL      0.0       0.9    15.0     20.0  0.977739  0.989664   \n",
       "1    2016postVFP_UL      0.0       0.9    20.0     25.0  0.984609  0.994829   \n",
       "126         2018_UL      2.1       2.4    60.0    120.0  1.001259  1.002989   \n",
       "127         2018_UL      2.1       2.4   120.0   1500.0  1.001259  1.002989   \n",
       "\n",
       "         sfup  \n",
       "0    1.001588  \n",
       "1    1.005048  \n",
       "126  1.004718  \n",
       "127  1.004718  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/muonsf/muon_iso_sf.txt\n",
      "\n",
      "--------------------------------------------------\n",
      "\u001b[032mProcessing corrections for: Jet-JEC\u001b[0m\n",
      "--------------------------------------------------\n",
      "\n",
      "\u001b[033mProcessing correction: Summer19UL18_V5_MC_Total_AK4PFchs\u001b[0m\n",
      "\n",
      "Opening file: POG/JME/2016postVFP_UL/jet_jerc.json for correction: Summer19UL18_V5_MC_Total_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2016preVFP_UL/jet_jerc.json for correction: Summer19UL18_V5_MC_Total_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2017_UL/jet_jerc.json for correction: Summer19UL18_V5_MC_Total_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2018_UL/jet_jerc.json for correction: Summer19UL18_V5_MC_Total_AK4PFchs\n",
      "Edges extracted!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.89860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.90785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5226.5</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>0.90875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7839</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>6538.0</td>\n",
       "      <td>0.90775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            campaign  eta_low  eta_high  pt_low  pt_high   sfdown   sf  \\\n",
       "0     2016postVFP_UL     -5.4      -5.0     9.0     11.0  0.89860  1.0   \n",
       "1     2016postVFP_UL     -5.4      -5.0    11.0     13.5  0.90785  1.0   \n",
       "7838         2018_UL      5.0       5.4  5226.5   5784.0  0.90875  1.0   \n",
       "7839         2018_UL      5.0       5.4  5784.0   6538.0  0.90775  1.0   \n",
       "\n",
       "         sfup  \n",
       "0     1.10140  \n",
       "1     1.09215  \n",
       "7838  1.09125  \n",
       "7839  1.09225  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/jetsf/jet_jec_sf.txt\n",
      "\n",
      "--------------------------------------------------\n",
      "\u001b[032mProcessing corrections for: Jet-JER\u001b[0m\n",
      "--------------------------------------------------\n",
      "\n",
      "\u001b[033mProcessing correction: Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs\u001b[0m\n",
      "\n",
      "Opening file: POG/JME/2016postVFP_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2016preVFP_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2017_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2018_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs\n",
      "Edges extracted!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-5.191</td>\n",
       "      <td>-3.139</td>\n",
       "      <td>1.0219</td>\n",
       "      <td>1.0672</td>\n",
       "      <td>1.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-3.139</td>\n",
       "      <td>-2.964</td>\n",
       "      <td>1.1283</td>\n",
       "      <td>1.1599</td>\n",
       "      <td>1.1914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>2.964</td>\n",
       "      <td>3.139</td>\n",
       "      <td>1.2063</td>\n",
       "      <td>1.2670</td>\n",
       "      <td>1.3278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>3.139</td>\n",
       "      <td>5.191</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>1.0367</td>\n",
       "      <td>1.1942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  eta_low  eta_high  sfdown      sf    sfup\n",
       "0    2016postVFP_UL   -5.191    -3.139  1.0219  1.0672  1.1125\n",
       "1    2016postVFP_UL   -3.139    -2.964  1.1283  1.1599  1.1914\n",
       "110         2018_UL    2.964     3.139  1.2063  1.2670  1.3278\n",
       "111         2018_UL    3.139     5.191  0.8792  1.0367  1.1942"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/jetsf/jet_jer_sf.txt\n",
      "\n",
      "--------------------------------------------------\n",
      "\u001b[032mProcessing corrections for: Jet-pT\u001b[0m\n",
      "--------------------------------------------------\n",
      "\n",
      "\u001b[033mProcessing correction: Summer19UL18_JRV2_MC_PtResolution_AK4PFchs\u001b[0m\n",
      "\n",
      "Opening file: POG/JME/2016postVFP_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_PtResolution_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2016preVFP_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_PtResolution_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2017_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_PtResolution_AK4PFchs\n",
      "Edges extracted!\n",
      "Opening file: POG/JME/2018_UL/jet_jerc.json for correction: Summer19UL18_JRV2_MC_PtResolution_AK4PFchs\n",
      "Edges extracted!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>rho_low</th>\n",
       "      <th>rho_high</th>\n",
       "      <th>sf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.240261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.22</td>\n",
       "      <td>13.26</td>\n",
       "      <td>0.278253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35670</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>6538.0</td>\n",
       "      <td>30.99</td>\n",
       "      <td>36.90</td>\n",
       "      <td>0.082722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35671</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5784.0</td>\n",
       "      <td>6538.0</td>\n",
       "      <td>36.90</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0.082482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             campaign  eta_low  eta_high  pt_low  pt_high  rho_low  rho_high  \\\n",
       "0      2016postVFP_UL     -4.7      -3.2     9.0     11.0     0.00      7.22   \n",
       "1      2016postVFP_UL     -4.7      -3.2     9.0     11.0     7.22     13.26   \n",
       "35670         2018_UL      3.2       4.7  5784.0   6538.0    30.99     36.90   \n",
       "35671         2018_UL      3.2       4.7  5784.0   6538.0    36.90     90.00   \n",
       "\n",
       "             sf  \n",
       "0      0.240261  \n",
       "1      0.278253  \n",
       "35670  0.082722  \n",
       "35671  0.082482  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/jetsf/jet_ptres_sf.txt\n",
      "\n",
      "--------------------------------------------------\n",
      "\u001b[032mProcessing corrections for: bJet\u001b[0m\n",
      "--------------------------------------------------\n",
      "\n",
      "\u001b[033mProcessing correction: deepJet_mujets\u001b[0m\n",
      "\n",
      "Opening file: POG/BTV/2016postVFP_UL/btagging.json for correction: deepJet_mujets\n",
      "Opening file: POG/BTV/2016preVFP_UL/btagging.json for correction: deepJet_mujets\n",
      "Opening file: POG/BTV/2017_UL/btagging.json for correction: deepJet_mujets\n",
      "Opening file: POG/BTV/2018_UL/btagging.json for correction: deepJet_mujets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>flav</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726181</td>\n",
       "      <td>0.863539</td>\n",
       "      <td>1.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615162</td>\n",
       "      <td>0.732491</td>\n",
       "      <td>0.849819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.735934</td>\n",
       "      <td>0.954257</td>\n",
       "      <td>1.172580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.749219</td>\n",
       "      <td>0.965463</td>\n",
       "      <td>1.181707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  eta_low  eta_high  pt_low  pt_high  flav    sfdown  \\\n",
       "0    2016postVFP_UL        0       2.5    20.0     30.0     0  0.726181   \n",
       "1    2016postVFP_UL        0       2.5    30.0     50.0     0  0.615162   \n",
       "106         2018_UL        0       2.5   300.0    600.0     4  0.735934   \n",
       "107         2018_UL        0       2.5   600.0   1000.0     4  0.749219   \n",
       "\n",
       "           sf      sfup  \n",
       "0    0.863539  1.000897  \n",
       "1    0.732491  0.849819  \n",
       "106  0.954257  1.172580  \n",
       "107  0.965463  1.181707  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/bjeteff/bjet_mujets_and_incl_eff.txt\n",
      "\n",
      "\u001b[033mProcessing correction: deepJet_comb\u001b[0m\n",
      "\n",
      "Opening file: POG/BTV/2016postVFP_UL/btagging.json for correction: deepJet_comb\n",
      "Opening file: POG/BTV/2016preVFP_UL/btagging.json for correction: deepJet_comb\n",
      "Opening file: POG/BTV/2017_UL/btagging.json for correction: deepJet_comb\n",
      "Opening file: POG/BTV/2018_UL/btagging.json for correction: deepJet_comb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>campaign</th>\n",
       "      <th>eta_low</th>\n",
       "      <th>eta_high</th>\n",
       "      <th>pt_low</th>\n",
       "      <th>pt_high</th>\n",
       "      <th>flav</th>\n",
       "      <th>sfdown</th>\n",
       "      <th>sf</th>\n",
       "      <th>sfup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726181</td>\n",
       "      <td>0.863539</td>\n",
       "      <td>1.000897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016postVFP_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.615162</td>\n",
       "      <td>0.732491</td>\n",
       "      <td>0.849819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.828379</td>\n",
       "      <td>0.930683</td>\n",
       "      <td>1.032986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2018_UL</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.684487</td>\n",
       "      <td>0.880405</td>\n",
       "      <td>1.076323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           campaign  eta_low  eta_high  pt_low  pt_high  flav    sfdown  \\\n",
       "0    2016postVFP_UL        0       2.5    20.0     30.0     0  0.726181   \n",
       "1    2016postVFP_UL        0       2.5    30.0     50.0     0  0.615162   \n",
       "106         2018_UL        0       2.5   300.0    600.0     4  0.828379   \n",
       "107         2018_UL        0       2.5   600.0   1000.0     4  0.684487   \n",
       "\n",
       "           sf      sfup  \n",
       "0    0.863539  1.000897  \n",
       "1    0.732491  0.849819  \n",
       "106  0.930683  1.032986  \n",
       "107  0.880405  1.076323  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to corrections/bjeteff/bjet_comb_and_incl_eff.txt\n",
      "\n",
      "Done!\n",
      "\n",
      "CPU times: user 19.5 s, sys: 336 ms, total: 19.8 s\n",
      "Wall time: 22.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for obj, val in objectdict.items():\n",
    "    \n",
    "    #if obj not in ['Electron']: continue ### For testing purposes\n",
    "    #if obj not in ['Jet-JEC', 'Jet-JER', 'Jet-pT']: continue ### For testing purposes\n",
    "\n",
    "    print(f'\\n'+'-'*50+f'\\n\\033[032mProcessing corrections for: {obj}\\033[0m\\n'+'-'*50)\n",
    "    basedir = val['basedir']\n",
    "    outdir = val['outdir']\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    campaigns = os.listdir(basedir) #list only folders, not files\n",
    "    files = []\n",
    "    for camp in campaigns:\n",
    "        if camp not in ['2018_UL', '2017_UL', '2016preVFP_UL', '2016postVFP_UL']: continue\n",
    "        filename = os.path.join(basedir, camp, val['jsonfile'])\n",
    "        if os.path.exists(filename) and filename.endswith('.json'):\n",
    "            files.append((filename, camp))\n",
    "    \n",
    "    for correction in val['corrections']:\n",
    "        print(f\"\\n\\033[033mProcessing correction: {correction}\\033[0m\\n\")\n",
    "        output_filename = val['corrections'][correction]\n",
    "        os.makedirs(val['outdir'], exist_ok=True)\n",
    "\n",
    "        data = []\n",
    "        for filename, campaign in files:\n",
    "            print(f'Opening file: {filename} for correction: {correction}')\n",
    "            if obj == 'Electron': extracted_data = parse_electron_sf(filename, correction, campaign)\n",
    "            elif obj == 'Muon':   extracted_data = parse_muon_sf(filename, correction, campaign)\n",
    "            elif obj == 'bJet':   extracted_data = parse_bjet_eff(filename, correction, campaign)\n",
    "            elif obj =='Jet-JEC':\n",
    "                if correction == 'Summer19UL18_V5_MC_Total_AK4PFchs':\n",
    "                    if   '2016preVFP'  in campaign: correction = 'Summer19UL16APV_V7_MC_Total_AK4PFchs'\n",
    "                    elif '2016postVFP' in campaign: correction = 'Summer19UL16_V7_MC_Total_AK4PFchs'\n",
    "                    elif '2017'        in campaign: correction = 'Summer19UL17_V5_MC_Total_AK4PFchs'\n",
    "                    extracted_data = parse_jet_jec_sf(filename, correction, campaign)\n",
    "                correction = 'Summer19UL18_V5_MC_Total_AK4PFchs' ### return to previous so that this loop can happen again.\n",
    "            elif obj == 'Jet-JER':\n",
    "                if correction == 'Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs':\n",
    "                    if   '2016preVFP'  in campaign: correction = 'Summer20UL16APV_JRV3_MC_ScaleFactor_AK4PFchs'\n",
    "                    elif '2016postVFP' in campaign: correction = 'Summer20UL16_JRV3_MC_ScaleFactor_AK4PFchs'\n",
    "                    elif '2017'        in campaign: correction = 'Summer19UL17_JRV2_MC_ScaleFactor_AK4PFchs'\n",
    "                    extracted_data = parse_jet_jer_sf(filename, correction, campaign)\n",
    "                correction = 'Summer19UL18_JRV2_MC_ScaleFactor_AK4PFchs'  ### return to previous so that this loop can happen again.\n",
    "            elif obj == 'Jet-pT':\n",
    "                if correction == 'Summer19UL18_JRV2_MC_PtResolution_AK4PFchs':\n",
    "                    if   '2016preVFP'  in campaign: correction = 'Summer20UL16APV_JRV3_MC_PtResolution_AK4PFchs'\n",
    "                    elif '2016postVFP' in campaign: correction = 'Summer20UL16_JRV3_MC_PtResolution_AK4PFchs'\n",
    "                    elif '2017'        in campaign: correction = 'Summer19UL17_JRV2_MC_PtResolution_AK4PFchs'\n",
    "                    extracted_data = parse_jet_ptres_sf(filename, correction, campaign)\n",
    "                correction = 'Summer19UL18_JRV2_MC_PtResolution_AK4PFchs' ### return to previous so that this loop can happen again.                    \n",
    "                \n",
    "            data.append(extracted_data)\n",
    "            \n",
    "        data = pd.concat(data, ignore_index=True)\n",
    "        columns_to_round = ['sfdown', 'sf', 'sfup']\n",
    "        existing_columns = [col for col in columns_to_round if col in data.columns]  ### Filter existing columns\n",
    "        if data.empty:\n",
    "            warning(f'Dataframe empty. Skipping correction: {correction}')\n",
    "            continue\n",
    "        data[existing_columns] = data[existing_columns].round(6)\n",
    "        display(pd.concat([data.head(2), data.tail(2)]))\n",
    "\n",
    "        outfile = os.path.join(val['outdir'], output_filename)    \n",
    "        with open(outfile, 'w') as f:\n",
    "            for index, row in data.iterrows():\n",
    "                ### Text formatting:\n",
    "                formatted_row = \"\"\n",
    "                for i, column in enumerate(data.columns):\n",
    "                    if i == 0:                       formatted_row += f\"{str(row[column]):<20}\"\n",
    "                    elif column in columns_to_round: formatted_row += f\"{str(row[column]):<12}\"\n",
    "                    else:                            formatted_row += f\"{str(row[column]):<8}\"\n",
    "                f.write(formatted_row.strip() + \"\\n\")\n",
    "\n",
    "        print(f\"Data written to {outfile}\")\n",
    "\n",
    "print('\\nDone!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8196a49-ed82-4ec9-a915-46686bbe6c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
